# from datasets import load_dataset
# from nltk.tokenize import word_tokenize, MWETokenizer
# df = load_dataset("ai4privacy/pii-masking-200k")
# print("Source")
# print(df['train']['source_text'][0])
# print("Target")
# print(df['train']['target_text'][0])
import numpy as np
import tensorflow as tf
print(tf.config.list_physical_devices())